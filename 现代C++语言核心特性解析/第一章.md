# 第一章 新基础类型

## long long 类型

C++标准定义`long long`是一个至少为64位的整数类型。
`long long`后缀`LL`, 如`12345678LL`。

字面量后缀并非没有意义，未声明后缀的字面量会被默认为int类型：

```cpp
long long x1 = 65536 << 16;               // 计算得到的x1值为 0
std::cout << "x1 = " << x1 << std::endl;
long long x2 = 65536LL << 16;             // 计算得到的x2值为 4294967296（0x100000000）
std::cout << "x2 = " << x2 << std::endl;
```

* 使用`<limits>`和`std::numeric_limits`获取极限值

```cpp
#include <iostream>
#include <limits>
#include <cstdio>
int main(int argc, char *argv[])
{
 // 使用宏方法
std::cout << "LLONG_MAX = " << LLONG_MAX << std::endl;
 std::cout << "LLONG_MIN = " << LLONG_MIN << std::endl;
 std::cout << "ULLONG_MAX = " << ULLONG_MAX << std::endl;
 // 使用类模板方法
 std::cout << "std::numeric_limits<long long>::max() = " 
 << std::numeric_limits<long long>::max() << std::endl;
 std::cout << "std::numeric_limits<long long>::min() = " 
 << std::numeric_limits<long long>::min() << std::endl;
 std::cout << "std::numeric_limits<unsigned long long>::max() = " 
 << std::numeric_limits<unsigned long long>::max() << std::endl;
 // 使用printf打印输出
 std::printf("LLONG_MAX = %lld\n", LLONG_MAX);
 std::printf("LLONG_MIN = %lld\n", LLONG_MIN);
 std::printf("ULLONG_MAX = %llu\n", ULLONG_MAX);
}
```

## 新字符类型`char16_t`和`char32_t`

* 字符集和编码方法

UTF-32的单个编码能够完全支持容纳任何一个字符编码，缺点在于单个编码长度过长。

UTF-16的单个编码不足以容纳总字符集(Unicode的最大个数为0x10FFFF——ISO 10646)。
映射方式：，从`0x0000～0xD7FF`以及`0xE000～0xFFFF`直接映射到Unicode字符集，而剩下的`0xD800～0xDFFF`则用于映射`0x10000～0x10FFFF`的Unicode字符集:字符编码减去0x10000后剩下的20比特位分为高位和低位，高10位的映射范围为0xD800～0xDBFF，低10位的映射范围为0xDC00～0xDFFF。

例如0x10437，减去0x10000后的高低位分别为0x1和0x37，分别加上0xD800和0xDC00的结果是0xD801和0xDC37。

UTF-8最常用的，是一种可变长度的编码方式。为了尽量节约空间，常用的字符通常用1～2字节就能表达，其他的字符才会用到3～4字节，所以在内存空间可以使用UTF-8，但是计算字符串长度和查找字符在UTF-8中却是一个令人头痛的问题。

* 使用新字符类型char16_t和char32_t

C++11标准还为3种编码提供了新前缀用于声明3种编码字符和字符串的字面量，它们分别是UTF-8的前缀`u8`、UTF-16的前缀`u`和UTF-32的前缀`U`

在C++11标准中u8只能作为字符串字面量如`"apple"`的前缀，而无法作为字符如`'a'`的前缀。这个问题直到C++17标准才得以解决。

`char utf8c = u8'好'`是无法通过编译的，因为存储“好”需要3字节，显然utf8c只能存储1字节，所以会编译失败。

* wchar_t存在的问题

在C++98的标准中提供了一个`wchar_t`字符类型，并且还提供了前缀L，用它表示一个宽字符。事实上Windows系统的API使用的就是·，它在Windows内核中是一个最基础的字符类型。

然而，起初在定义wchar_t时并没有规定其占用内存的大小。于是就给了实现者充分的自由，以至于在Windows上wchar_t是一个16位长度的类型（2字节），而在Linux和macOS上wchar_t却是32位的（4字节）。这导致了一个严重的后果，严重影响了代码的可移植性。

* 新字符串链接


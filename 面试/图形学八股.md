# 图形学八股

## 管线

### 管线综述

将顶点和相关信息输入，这一部分发生在vertex shder，将模型从模型坐标转化为世界坐标，再转换为摄像世界坐标，然后进入Hull Shader和 Tessellation.
**Hull shader**主要作用：定义一些细分的参数（如：每条边上如何细分，内部三角形如何细分）.
Hull Shader由两部分组成，*Constant Hull Shader*：对于每一个patch都会执行一次这个constant hull shader，其功能是用来输出所谓的细分因子(tessellation factor).细分因子用于在tessellation 阶段告诉硬件如何对patch进行细分。
*control point hull shader*使用多个控制点作为输入(原始模型顶点)，并且输出多个控制点。每输出一个控制点都会调用一次 control point hull shader。通常在hull shader阶段输出的控制点数目和输入的控制点数目一致，除非我们要改变模型的几何结构，例如把一个三角面输出为一个三阶贝塞尔曲面。真真正的曲面细分实在下一个tessellation stage完成的。

**Tessellation Primitive Generator**：不可编程的，只能配置。
**Domain shader**：经过曲面细分着色器细分后的点是位于重心空间的，这部分的作用就是把它转化到我们要用的空间。

**Geometry Shader**的输入为单个Primitive或是多个，主要作用就是从已有的primitive中生成新的primitive，比如生成粒子等。

**Perspective Transfermation**阶段，对于模型进行视角变换并通过z-buffer进行转化为2D，这一部分是完全可编程的。z-buffer使用z深度缓存和帧缓存器，z缓存存储每个像素对应的深度值，帧缓存存储像素的颜色值。对于每个图元内部的采样点，计算深度值并更新缓存，最终生成相应的帧。

结束z-buffer后，进入的下一阶段**Clipping**和**backface culling**是不可编程的，首先把不在视锥体内或不完全在的三角形清除或剪切。输出裁切后的顶点。其次移除没有面对这镜头的三角形，只考虑三角形与摄像机的相对位置而不依赖与摄像机朝向。依靠三角形顶点顺序直接判断法向量方向。
在culling阶段，设置正面三角形的顶点连接方式，顺时针还是逆时针，通过左手坐标系和叉乘判断三角形的方向，进行剔除，这样只需要进行一次叉乘。

接下来就是**rasterization**阶段，在裁切后，顶点会投影到屏幕坐标。概念性的有以下5个执行步骤：
插值（*Interpolate*），大部分计算如：顶点级别的纹理坐标、颜色、法线都要在着色前计算好。
深度测试（*Depth test*），剔除掉被遮住的像素。这里计算也可能是在着色后计算。
着色（*Shader*）：为像素计算颜色。一般先光照后雾化，输出的颜色包含透明值，即RGBA。
透明测试（*Alpha test*），丢弃过度透明的物体。有透明的物体不需要写入深度缓冲。
写入（*Write*），通过深度和透明测试的像素，会更新帧缓存和深度缓冲。深度缓存用新值直接替换旧值。帧缓存没有开启混合，则可直接替换，否则需要用alpha值混合。

**early-Z**提前深度测试, 在光栅化和片元阶段中间，加入一个early-z阶段。这个阶段进行的操作和原本逐像素处理阶段的z-test（为了与early-z区别，这个阶段也会被成为late-z）操作完全一样。early-z是以pixel quad为单位（既以4个像素为一组，因为深度缓存内的数据是按Z字形排列的）
在以下几种常见情况中Early-Z会失效：开启Alpha Test或者clip、discard等手动丢弃片元操作；手动修改GPU插值得到的深度；开启Alpha Blend；关闭深度测试Depth Test。
有人说UE的early-Z其实也是Z-prepress。

在将材质读入cache后，并与光栅化阶段提供的材质坐标共同输入进入**texture filtering**,采集到的texels会与pixel shader共同进行像素着色。

完成**fragment shader**阶段后，会进入**z-test**和**alpha blending**, 这都是不可编程的。
**z-test**最后一次根据像素值和深度值进行比较，通过了会将颜色写入颜色缓冲区。
**alpha blending**在渲染半透明物体时将其颜色与背景进行混合，从而产生透明效果。在透明度混合中，每个像素的输出颜色是由物体颜色和背景颜色按照一定比例混合而成，这一比例通常由物体的透明度值（Alpha值）来控制。

接下来是**anti-alising**进行抗锯齿，比如fxaa。

最后进入后处理阶段。

### 针对z-buffer的改善

**A-缓存器算法**
对Z-buffer进行扩展，使每个单元对应一个多边形列表而非单一深度值。这样，可以记录多个影响同一像素的多边形，处理透明和半透明效果，同时支持反走样。

解决了对于透明和半透明处理的局限性。

**区间扫描线算法**
子区间划分：将扫描线按照多边形边界分割为子区间，每个子区间内仅有一个可见面。
深度计算与颜色更新：在每个子区间内，找出深度最大（最近）的多边形，根据其光照属性和几何位置确定子区间内像素的颜色。
边表与多边形表：构建边表和多边形表，用于高效查找子区间内的可见多边形。

显著减少了存储需求，仅对非空子区间进行采样和深度计算，避免了对于被遮挡区域的无效计算。

### z-prepass 和 early-z

z-prepass是一种软件技术。它主要是配合early-z使用，来减少开始提到的early的缺点——效果不稳定。
其做法是将场景做两个pass的绘制。第一个pass仅写入深度，不做任何复杂的片元计算，不输出任何颜色。第二个pass关闭深度写入，并将深度比较函数设为“相等”。

那么对于第一个pass由于只写入深度，不在片元做任何计算，所以即便之后会被丢弃，也并不可惜。也就是说无论场景中的物体以怎样的顺序绘制，我们都可以以很小的代价提前绘制好当前场景的深度缓存。那么在第二个pass时，early-z就可以用这个深度缓存中的值和当前深度值进行比较，只绘制深度相等的片元，任何其他的片元都可以直接丢弃，因此第二个pass要把深度比较函数设为“相等”。同时当前的深度缓存已经是完全正确的结果了，因此第二个pass也不需要对深度缓存做任何更新，便可以关闭深度写入。

z-prepass必须配合early-z才能发挥效果，如果没有early-z的话，第二个pass的深度测试依旧在片元后，因此所有片元都会在片元阶段进行复杂计算。

**和延迟渲染的区别**
z-prepass的思想和延迟渲染管线（defered render pipeline）有些相似，差别在于：第一，z-prepass的第一个pass只计算深度，并且结果直接存储在深度缓存。而延迟渲染会同时计算更多其他的屏幕空间数据，并将这些数据存储在额外的framebuffer中，需要更大的缓存（也就是GBuffer）。第二，z-prepass的第二个pass依旧需要对全场景的各个物体进行绘制（至少顶点阶段是如此），而延迟渲染的第二个pass类似于后处理本质上只绘制了一个屏幕大小的矩形。

### Early-Z失效

以下情况会导致Early-Z失效：

1. 开启Alpha Test：由于Alpha Test需要在像素着色器后面的Alpha Test阶段比较，所以无法在像素着色器之前就决定该像素是否被剔除。
2. 开启Tex Kill：即在shader代码中有像素摒弃指令（DX的discard，OpenGL的clip）。
3. 关闭深度测试。Early-Z是建立在深度测试看开启的条件下，如果关闭了深度测试，也就无法启用Early-Z技术。
4. 开启Multi-Sampling：多采样会影响周边像素，而Early-Z阶段无法得知周边像素是否被裁剪，故无法提前剔除。
以及其它任何导致需要混合后面颜色的操作。

### 深度测试和模板测试

模板测试

### shading

#### forward rendering

当我们渲染模型时，只需要关心画模型然后直接处理光照，让它自己去做深度测试，最后深度测试过的都显示在屏幕上。

1. 对要渲染的物体进行遍历渲染出shadowmap
2. 再遍历一遍上面要渲染的物体，根据shadowmap对每一个物体的像素进行光照计算

**优点**:
很明显，就是简单，并且可以针对每个物体指定它的材质，因为每个物体都是独立渲染的。

**缺点**:
1、由于依赖深度测试，如果物体是乱序的，可能会出现大量的像素光照计算都是浪费的。
2、不能支持光源数量较多的情况。所以我们一般有两种做法来处理多光源的情况，一种是一遍渲染多个光源，所有光照运算都在一个着色器中进行。另一种是多遍渲染多个光源，意思就是每多一盏灯，就多渲染一次模型，所以性能消耗也比较大。

#### Deferred rendering

它的做法是在第一遍渲染模型的时候，不进行光照计算，直接将位置、法线深度、颜色等存到G-Buffer。
也就是说一次渲染，需要输出多张纹理，这跟前向渲染是不同的， 前向渲染只渲染到一张纹理上，这张纹理最终会渲染在屏幕上。而延迟渲染这多张纹理都不是最终结果，可以理解为只是用几张贴图存储一堆中间数据。
第二遍再根据G-Buffer的数据，进行光照计算，写入帧缓冲区.

很多人第一次接触G-Buffer这个名词都是一头雾水，其实就是创建多张和屏幕一样大的纹理，然后每张纹理的像素值分别用来存上面提到的这些数据。

![Alt](./res/defered_shading.png#pic_center)

**优点**：
处理完G-Buffer之后，其实每盏灯光就可以通过一个Drawcall的消耗去执行光照计算。第一遍处理完的G-Buffer是深度测试过的，不像前向渲染一样，有那么多光照计算的浪费。

1. 多光源支持良好， 在大量光源的场景优势尤其明显。
2. 解耦了Mesh Draw和Light Draw，保证物体只被绘制一次，光源也只绘制一次，整体场景Draw call复杂度变成了O(M+N)。
3. G-Buffer除了用于直接光照外，还能够被用于一些间接光照的效果，也正是G-Buffer概念的提出，使得近十年来越来越多的算法从World space向Screen Space的演进。
4. 由于上面的解耦。使得每个着色器都专注于几何参数提取或者照明。这种分离使着色器的功能进行拆分，简化了着色器系统管理。使得Shader支持功能更加单一(这是优点也是缺点)
5. 只渲染可见的像素，节省计算量

**缺点**：
1、最终的光照计算方式只能是一种，也就是其他文章提到的只允许一个材质，因为最终计算的时候只剩下一堆数据，不知道它们分别是谁的，所以只能无差别对待。而前向渲染可以每个模型一种计算方式。
2、不允许使用透明物件，因为最终G-Buffer只剩一个像素了，无法进行混合。不过可以在第二遍渲染完之后，用前向渲染的方式渲染透明物体。
3、不支持抗锯齿，意味着不能用MSAA，不过可以用FXAA进行后期处理
4、有些硬件不支持MRT(Multiple Render Targets 多重纹理目标)，也就是输出到多张纹理上实现G-Buffer的功能
5、G-Buffer需要比较大的带宽，有些硬件没不具备这个能力
6、由于光照计算本身性能消耗也不低，延迟渲染的光照计算其实等同于在做一次全屏的后处理，后处理其实对手机来说过于昂贵。而如果只有一盏灯的话，其实前向渲染省了这次额外的渲染。所以移动设备上延迟渲染的性能会比前向渲染的性能要差一些

#### Forward+ rendering

Forward+方法相对于传统的前向方法在最终的着色阶段前添加了一个光源剔除阶段(light-culling stage)。
Forward+方法的渲染管线包含3个**阶段**：depth prepass，光源剔除(light culling)和最终的着色(shading)阶段。
Forward+方法对**存储光源信息**的数据结构也作了修改，将光源信息存储在一个线性布局的缓冲中，方便进行光源剔除和在最终的着色阶段访问使用。**depth prepass**是前向渲染的一个可选优化。
 对于Forward+来说，使用depth prepass可以大大减少最终着色阶段的压力。如果将depth prepass和延迟方法的G-prepass进行比较，前向渲染的depth prepass只使用了深度缓冲，要比G-prepass的计算代价小。

![Alt](./res/forwardplus_shading.png#pic_center)

**Depth PrePass**和Early Z的效果一致, 可以减少OverDraw。

**Light Culling**: 这里将屏幕划分为16X16(在这里大多数项目都是使用的16X16)。在每个Tile当中寻找各自影响该Tile的光源。形成一个Light List,后续在该Tile中的Pixel只需要计算在Light List中的光源对该Pixel贡献即可.
需要一个Compute Shader来计算，依据是当前Tile的Screen Position和Depth Bound(基于这两个信息可以计算出view frustum)

#### 合批渲染

Batch就是调用一次API的绘制接口向GPU提交相同渲染状态的一定数量的三角形的行为。
Batch等于一堆打包后的Draw call。

**作用**: 批量渲染是通过减少CPU向GPU发送渲染命令（DrawCall）的次数，以及减少GPU切换渲染状态的次数，尽量让GPU一次多做一些事情，来提升逻辑线和渲染线的整体效率。

合批渲染主要分为静态合批和动态合批：

**静态合批**: 对于一部分静态物体且使用相同材质，对其自动合并为一个batch送往GPU处理。使用静态合批需要额外的内存开销来存储合并后的几何数据。如果一些物体共用了同样的几何数据，那么引擎会在编译以及运行状态对每个物体创建一个几何数据备份。

原理：
1.自动提取这些静态模型的VertexBuffer和IndexBuffer
2.根据其在场景中的位置等最终状态信息，将这些模型的顶点数据变换到世界空间下
3.重新构建大的VertexBuffer和IndexBuffer
4.记录每一个子模型的IndexBuffer数据在构建大的IndexBuffer的起始以及结束。

**动态合批**:
将数份Mesh的数据复制粘贴到一起，也就是实时的，每一帧都合并，用复制数据的性能消耗换取提交Drawcall的性能消耗。
动态合批在绘制前会先将顶点转换到世界坐标系下，然后再填充进顶点、索引缓冲区.
动态合批不会创建常驻内存的“合并后网格”，也就是说它不会在运行时造成内存的显著增长，也不会影响打包时的包体大小。
动态合批的主要开销在于遍历顶点进行空间变换时的对CPU性能的开销。

##### GPU实例化

实例化没有动态合批那样对网格数量的限制，也没有静态网格那样需要这么大的内存，它很好的弥补了这两者的缺陷，但也有存在着一些限制。

GPU Instancing 并不通过对网格的合并操作来减少Drawcall，GPU Instancing 的处理过程是只提交一个模型网格让GPU绘制很多个地方，这些不同地方绘制的网格可以对缩放大小，旋转角度和坐标有不一样的操作，材质球虽然相同但材质球属性可以各自有各自的区别。



### G-Buffer的压缩

GBuffer中需要存储的必要信息。其中包括BaseColor,WorldNormal,Metallic,Roughness等必要的信息。
对于**Metallic**和**Roughness**，是单通道，相对比较固定简单。
**BaseColor**则涉及到不同颜色的编码，需要选择更合理的编码来用于不同的压缩形式。

首先每张RT有RGBA四个通道，每个通道是8bit，那么总共是4*8=32bit的通道信息.

### 顶点属性太多，槽位不够怎么办？

使用一个大buffer存struct然后顶点属性只用存buffer的索引.

## 光线

### Blinn-Phong反射模型计算光照强度

分为三种光照，Specular,diffuse以及ambient
镜面反射光是一个Lobe相对较窄的立体角，具体表现为只有在与反射光角度相近的地方才能观察到，与观察角度又管
漫反射在该模型中被定义为会被物体表面反射到各个方向去，因而视觉效果不受观察方向影响，与观测角度没有关系
环境光一般被处理成一个常数直接着色。

在该模型中，获取一个表面的光照需要以下输入：
单位向量：

1. 入射光向量$\omega_i$
2. 法线向量$\bold{n}$
3. 出射光向量$\omega_o$

以及着色属性：色彩和纹理坐标
最后是光源属性： 光照强度，光源距离

### 给出法线和平行光的方向，如何计算平行光的强度

根据光源的功率和到达物体表面的距离，可以计算出该光源到达该点时的强度衰减，一般来说光线强度的衰减随着距离的平方正比。
最后根据法线计算光线在相对于物体表面的垂直分量上的入射强度。

### 点乘叉乘区别

点乘得到的结果是一个数值；叉乘得到的结果是一个向量。
点乘是两个向量的模的乘积再乘上两个向量夹角的余弦值；叉乘的大小(模)是两个矢量的模的乘积再乘上这两个向量夹角的正弦值。

叉乘只适用于三维空间，而点乘适用于任意维度的向量。
叉乘的结果向量垂直于原来的两个向量所在平面，而点乘没有明显的方向性。

### 射线线段求交

对于射线方向向量d与线段AB

1. 判断是否平行(叉乘)。
2. 假设存在交点P，则存在AP与AB成比例u
3. u<0或u>1都说明不想交
4. 计算出OP的长度t，可知$P = O+t*d$计算出交点坐标。

$P = O+t*d = A + u * AB$所以要求的是u和t的二元方程组。进一步使用克拉默法则进行优化。

### 射线三角形求交

Möller-Trumbore算法(MT算法)

1. 判断射线方向与三角面所在平面是否共面(算出法线，两边叉乘，然后用法线和)。
2. 假设射线在三角形面上的交点为P，计算AP在AB方向的比例u和在向量AC方向的比例v
3. 该比例系数同样应当位于0到1之间。需要注意的是u+v应当小于等于1。
4. 计算出OP的长途，并进一步使用克拉默法则优化方程组的计算。

### 三角形相交

对于两个三角形$T_1 = p_1p_2p_3$和$T_2 = q_1q_2q_3$，首先检查每个三角形与另一个三角形所在平面是否相交，如果相交，则说明有进一步两个三角形相交的可能性，那么一定会存在一条交线段。
Guigue和Devillers的方法被提出用于解决该问题。

首先定义一个行列式：

$$
[a, b, c, d] = (d - a)\cdot((b-a)\times(c-a))
$$

通过计算$[q_1, q_2, q_3, p_1]$，$[q_1, q_2, q_3, p_2]$和$[q_1, q_2, q_3, p_3]$
如果这些行列式的符号相同且非零，那么就没有交集，测试结束。如果全部为零，则三角形共面。

### 球面上两点之间的弧长

假设球的半径为R，所给定的2点为A，B两点，先假设A在北半球，B在南半球。
假设球心为点O，那么最后得到的$∠AOB$的弧度乘以球的半径R即为所求的球面距离。
设经过球的南极和北极的极点的直线为$l$，分别过点B、A作l的垂线，设垂点分别为D、C。
过点B作线BC的平行线BE，过C作BD的平行线CE，这两条平行线必定相交，交点为E，容易证明BDCE是一个矩形，同时，因为BE垂直AC且垂直EC，所以三角形AEB为直角三角形。 由于A、B点的经纬度已知，所以$∠OBD$和$∠OAC$也已知，
设分别为$β，α$，由于半径R已知，
所以$|BD| = R * cosβ$，$|AC| = R * cosα$，$|OD| = R * sinβ$，$|OC| = R * sinα$。
由于点A、B的经度已知，所以不难求出∠ACE的值。所以三角形ACE中不难用余弦定理求出|AE|的值。 
在直角三角形ABE中，容易求出AB的值。此时三角形AOB三条边都已知，所以∠AOB也可以用余弦定理求出来。

## 遮挡剔除

### Hi-Z遮挡剔除

Hi-Z Culling Hiz的全称是Hierarchical-Z map based occlusion culling。本算法主要分为四步：
**遮挡缓冲区生成**将所有主要遮挡物的深度渲染到遮挡缓冲区，根据设定的分辨率，低分辨率更容易遮挡小道具。全分辨率会因为相机移动导致剔除不正确
**Hierarchical-Z mipmap生成**： 创建遮挡缓冲区的Hierarchical-Z mipmap，使用max运算符生成每个mip级别。
**计算着色器判断可见性**: 将实例的数据打包到结构化缓冲区中：世界空间下的包围盒信息。你可以把视锥体剔除和遮挡剔除都继承到GPU上，此时需要将视锥体六个面传到计算着色判断包围盒是否在视锥体内即可。
**绘制可见实体**

## 动态mipmap

### 运行时生成纹理mipmap

运行时生成完整的纹理Mip链，而不是从纹理文件加载脱机生成的mip贴图，这种方式通常不适用于存储在磁盘上的纹理，该技术用于在运行时生成纹理。
`vkCmdBlitImage()`可以接受不同格式的图像并展开或缩小需要复制的区域，当这些区域写入到目标图像时。术语blit是 block image transfer的缩写，指不仅需要复制图像数据，并且也可能需要在此过程中处理数据。
大致过程：

1. 加载第一级的纹理图片并计算mip等级
2. 生成Mip链
3. 最终图像布局过渡
4. 图像视图创建

具体步骤：

1. 计算LOD等级，就是通过长宽的$Log_2$进行计算，在Image初始化时提供并安排内存，接下来是常规的图像生成过程，将磁盘中的图像数据上传到设备内存，并设置图像内存barrier，修改Layout。
2. 生成mip链有两种不同的方法。第一种是将整个mip链从n-1级降低到n级，另一种方式是始终使用基本图像，然后从基础级降低到所有级别。
遍历Image对象的每一个mipmap等级，使用VkImageBlit为从Mip级i-1到i级的每个blit准备了一个结构。
blit源的尺寸由srcOffset指定：
设置了baseMipLevel子资源范围的成员，因此图像内存屏障将仅影响我们要复制到的一个Mip级别。
vkCmdBlitImage 使用线性滤波器将（降低）从Mip级别（i-1）缩放到Mip级别（i）。
绘制完成后，可以将此Mip级别用作下一级别的基础，因此可以将布局从转换为TRANSFER_DST_OPTIMAL
3. 循环完成后，将图像的所有Mip级别转换为它们的实际使用布局。并且在循环之后，所有级别都将位于TRANSER_SRC布局中，从而使我们可以立即传输整个图像。提交该命令缓冲区将导致图像具有完整的Mip链，并且所有MIP级别都将转换为用于着色器读取的正确图像布局。
4. 绑定资源并进行渲染和采样。

```cpp
VkImageBlit imageBlit{};

// Source
imageBlit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
imageBlit.srcSubresource.layerCount = 1;
imageBlit.srcSubresource.mipLevel = i-1;
imageBlit.srcOffsets[1].x = int32_t(texture.width >> (i - 1));
imageBlit.srcOffsets[1].y = int32_t(texture.height >> (i - 1));
imageBlit.srcOffsets[1].z = 1;
```

### 手动计算mipmap等级

使用ddx，ddy分别计算屏幕空间中x轴向和y轴向的给定值的偏导， 偏导数就正好是计算的这一块像素中的变化率。
使用模型表面的UV作为参数，使用ddx和ddy求其偏导，就可以得到在纹理空间下，相邻屏幕像素的UV差值，显而易见，相邻像素的UV差值越大，说明采样的纹理在屏幕上占比越小，对应的就需要使用mipmap level更大的mipmap等级进行纹理采样。

```glsl
tex2D(sampler2D tex, float2 uv)
{
  float dx=ddx(uv);
  float dy=ddy(uv);
  // texSize.xy为纹理tex的纹素大小
  // texSize.xy=1.0/float2(texWidth,texHeight)
  float px = texSize.x * dx;
  float py = texSize.y * dy;
  float lod = 0.5 * log2(max(dot(px, px), dot(py, py)));
  uv.w= lod;
  return tex2Dlod(tex, uv);
}
```

## 抗锯齿

### MSAA原理

全称是多重取样抗锯齿(Multisampling Antialising).
在光栅化阶段，在一个像素区域内对使用多个子采样点，但是每个像素内的这些子采样点共享一个着色计算，即是每个像素仍然只执行一次片断着色（Fragment shading）的计算，然后将计算的颜色结果复制到每个子采样点上。
简而言之，MSAA是把像素扩大N倍，得到N个子采样点，再将扩大成N倍的渲染目标，再经过一个过程缩放成原始的渲染目标，这个过程称为resolve。

### FXAA

原理步骤为：

1. 首先将图像转变为亮度图像
2. 使用描边算子进行描边计算，得到边缘的值:SkySnow：图像描边（索贝尔、拉普拉斯、罗伯特、普洱瑞斯）
3. 计算最大的亮度值与最小的亮度值，如果其亮度差值的计算大于规定阈值，则进行边缘模糊计算
4. 对x方向的亮度差值进行计算，对y方向的亮度差值进行计算，比对两个方向的亮度差值大小，以确定锯齿边缘的走向是垂直还是水平
5. 按照x或者y方向进行不同大小的步进进行计算亮度值，根据不同的亮度值判定选择不同的x或者y方向的模糊均值操作
6. 最后控制模糊的次数，分为四次模糊两次模糊，八次模糊等来控制边缘锯齿的控制

### MSAA可以在延迟渲染上做吗

使用G-buffer实现MSAA是不现实的，因为一个模型的材质数据(Albedo、深度、法线等)所需要的数据体量和带宽消耗都会加倍，对于高分辨率渲染来说几乎难以实现。

在vulkan中实现延迟渲染流程中的MSAA，分为几步：

1. 初始化阶段查询硬件的多重采样级数
2. 在shader中通过texelFetch采样各个LOD级别的纹素
3. 对纹素进行进行颜色合成

在外部通过pipeline的推入常量来控制多重采样级数，在着色器中，主要是用过texelFetch来采样不同级别的lod纹理，之后进行平均化处理来模拟MSAA颜色均衡输出。

**结果可能不正确**：
msaa是在ssaa的基础上发展而来的，通过测试的子像素才能复制中心像素的颜色，一个像素只计算一次，最后再写入颜色缓冲区。
再延迟渲染中，这个像素周围的信息已经丢失了，无法进行采样了，那么有没有办法解决这个问题呢：

在计算得到每一张G-buffer的时候，执行一遍子像素测试，这时候的每一张G-buffer都是取完插值的结果，这时候就保留了每一个像素的周边情况，最后再和光照做计算就没问题

但是，插值得到保留法线和深度的G-buffer可能插值不正确.

### MSAA带宽问题

MSAA会增加内存使用和带宽需求，因为它需要存储多个子像素的颜色和深度信息。它对性能的影响与采样数量成正比，采样数量越多，性能开销越大。

现在考虑MSAA在移动端的支持情况，现在的移动端的GPU架构，通常为TBR（Tile Based Rendering）或TBDR（Tile Based Deferred Rendering）。TBR将需要渲染的画面分成一个个的矩形区块（tile），矩形区块一般是4x4或者8x4，区块内包含相应的frame buffer/depth buffer/stencil buffer等信息。执行光栅化和像素操作时不需要反复的访问frame buffer、depth buffer、stencil buffer，GPU可以把整个区块读取进高速缓存（所谓的on-chip memory）中，这样GPU就直接访问区块，而不需要访问外部内存。这大大减少了内存的带宽消耗，也意味着能耗的降低。

对于MSAA技术而言，额外采样点所需要的所有数据，都存储在区块内，这就不会有带宽的额外消耗，效率是非常高的，多个采样点的resolve效率也是很高的。
Vulkan支持保存未被resolve的渲染结果。

## 阴影

**Shadow Mapping**的原理是首先将场景从光源的视角进行深度图的渲染，然后再从观察者的视角进行渲染，并使用深度比较来检测可见性并生成阴影。
将深度信息保存，并将结果存入一个纹理，作为阴影贴图。

**精度问题**：在shadow mapping 由光源点生成的一张深度图中，由于深度图的本质是一张纹理，而纹理是一种离散化的数字信号，从深度图还原源场景深度信息时难免对发生精度不同的问题。因为shadow Map产生的深度图的分辨率有限。
解决方案是容忍一段区间的遮挡物，即将阴影图中的深度值偏移一段。这一段距离就称为bias。

**走样问题**：单一的shadowmap会存在精度不足，为了性能和效果提出cascade shadowmap技术。

### CSM

将摄像机的视锥体划分为多个子视锥体：将摄像机的视锥体沿着近裁剪面到远裁剪面进行划分，将每个子视锥体映射到一个具有固定大小的2D矩形区域内。
对于每个子视锥体，渲染深度贴图：对于每个子视锥体，使用投射矩阵将场景渲染到一个深度贴图中，并保存深度值信息。
计算阴影：对于每个像素，使用与Shadow Mapping类似的算法来比较深度贴图中对应点的深度值和当前像素与光源的距离，来判断该像素是否被阴影所遮盖。
合并结果：将所有子视锥体的阴影贴图进行合并，并将阴影应用于场景中的对象。

### PCF相对于传统的shadow mapping做了哪些改变

之前的ShadowMapping过程中，假设现在得到了一张阴影图，接下来需要对一个着色点的深度和阴影图的采样结果作比较，得到一个二元的结果即为在阴影中为1，不在阴影中为0。正因为这种二元性，才产生了硬阴影的没有过渡（或者说走样现象）。

**PCF的做法**是得到阴影图后，选择一个以该着色点映射在阴影图中的位置为中心的$n*n$的filtering（核），用这个着色点的深度值分别和filtering中每个深度值的采样结果进行比较,最后得到一个$n*n$的二元比较结果，再对这个$n*n$的二元的比较结果进行filter（平均），最终得到这个着色点的阴影可见性的值，而这个结果不再是非0即1的值，而是一个在(0,1)之间的浮点数。

PCF技术通过对阴影贴图进行采样的方式，对像素周围的多个采样点进行插值和混合，从而更加准确地确定每个像素点的阴影强度。
具体而言，PCF方法将每个像素的阴影采样点划分为一个网格区域，并在每个区域内进行多个采样。通过对这些采样点的深度值进行比较和插值，可以得到一个更加平滑和准确的阴影效果。

## GPU逻辑管线

![Alt](./res/GPU_pipeline.png#pic_center)

下面介绍的是Fermi架构的管线

1. 程序通过**图形API**(DX、GL、WEBGL、VK)发出drawcall指令，指令会被推送到驱动程序，驱动会检查指令的合法性，然后会把指令放到GPU可以读取的**Push buffer**中.
2. 经过一段时间或者显式调用flush指令后，驱动程序把Pushbuffer的内容发送给GPU，GPU通过主机接口（**Host Interface**）接受这些命令，并通过前端（**Front End**）处理这些命令。
3. 在图元分配器(**Primitive Distributer**)中开始工作分配，处理indexbuffer中的顶点产生三角形分成批次(batches)，然后发送给多个GPCs(Graphics Processing Cluster)。这一步的理解就是提交上来n个三角形，分配给这几个GPC同时处理。
4. 在GPC中，每个SM中的Poly Morph Engine负责通过三角形索引(triangle indices)取出三角形的数据(vertex data)，即Vertex Fetch模块。
5. 在获取数据之后，在SM中以32个线程为一组的线程束(Warp)来调度，来开始处理顶点数据。Warp是典型的单指令多线程（SIMT，SIMD单指令多数据的升级）的实现，也就是32个线程同时执行的指令是一模一样的
6. SM(Stream Multiprocessor)的warp调度器会按照顺序分发指令给整个warp，单个warp中的线程会锁步(lock-step)执行各自的指令，如果线程碰到不激活执行的情况也会被遮掩(be masked out)。
7. warp中的指令可以被一次完成，也可能经过多次调度，例如通常SM中的LD/ST(加载存取)单元数量明显少于基础数学操作单元。
8. warp调度器可能会简单地切换到另一个没有内存等待的warp，这是GPU如何克服内存读取延迟的关键，只是简单地切换活动线程组。为了使这种切换非常快，调度器管理的所有warp在寄存器文件中都有自己的寄存器。
9. 一旦warp完成了vertex-shader的所有指令，运算结果会被Viewport Transform模块处理，三角形会被裁剪然后准备栅格化，GPU会使用L1和L2缓存来进行vertex-shader和pixel-shader的数据通信。
10. 接下来这些三角形将被分割，再分配给多个GPC，三角形的范围决定着它将被分配到哪个光栅引擎(raster engines)，每个raster engines覆盖了多个屏幕上的tile，这等于把三角形的渲染分配到多个tile上面。也就是像素阶段就把按三角形划分变成了按显示的像素划分了。
11. SM上的Attribute Setup保证了从vertex-shader来的数据经过插值后是pixel-shade是可读的。
12. GPC上的光栅引擎(raster engines)在它接收到的三角形上工作，来负责这些这些三角形的像素信息的生成（同时会处理裁剪Clipping、背面剔除和Early-Z剔除）。
13. 32个像素线程将被分成一组，或者说8个2x2的像素块，这是在像素着色器上面的最小工作单元，在这个像素线程内，如果没有被三角形覆盖就会被遮掩，SM中的warp调度器会管理像素着色器的任务。
14. 接下来的阶段就和vertex-shader中的逻辑步骤完全一样，但是变成了在像素着色器线程中执行。 由于不耗费任何性能可以获取一个像素内的值，导致锁步执行非常便利，所有的线程可以保证所有的指令可以在同一点。
15. 最后一步，现在像素着色器已经完成了颜色的计算还有深度值的计算，在这个点上，我们必须考虑三角形的原始api顺序，然后才将数据移交给ROP(render output unit，渲染输入单元)，一个ROP内部有很多ROP单元，在ROP单元中处理深度测试，和framebuffer的混合，深度和颜色的设置必须是原子操作，否则两个不同的三角形在同一个像素点就会有冲突和错误。

## 空间数据结构

### 四叉树/八叉树

本质上是同根同源的东西，基本思想是将地理空间递归划分为不同层次的树结构。
基本思想是将地理空间递归划分为不同层次的树结构。将已知范围的空间等分成四个相等的子空间，如此递归下去，直至树的层次达到一定深度或者满足某种要求后停止分割，复杂度O(logN)

```cpp
//示例：一个四叉树节点的简单结构
struct QuadtreeNode {
  Data data;
  QuadtreeNode* children[2][2];
  int divide;  //表示这个区域的划分长度
};

//示例：找到x,y位置对应的四叉树节点
QuadTreeNode* findNode(int x,int y,QuadtreeNode * root){
  if(!root)return;

  QuadtreeNode* node = root;
  
  for(int i = 0; i < N && n; ++i){
    //通过diliver来将x,y归纳为0或1的值，从而索引到对应的子节点。
    int divide = node->divide;
    int divideX = x / divide;
    int divideY = y / divide;
    
    QuadtreeNode* temp = node->children[divideX][divideY];
    if(!temp){break;}
    node = temp;
    
  //如果归纳为1的值，还需要减去该划分长度，以便进一步划分
  x -= (divideX == 1 ? divide : 0);
  y -= (divideY == 1 ? divide : 0);
  }
  
  return node;
}
```

### 松散四叉树/八叉树

四叉树/八叉树的一个问题是，物体有可能在边界处来回，从而导致物体总是在切换节点，从而不得不更新四叉树/八叉树。
定义一个节点有入口边界(inner boundary)，出口边界(outer boundary)。

**工作方式**：
若物体还没添加进四叉树/八叉树，则检测现在位于哪个节点的入口边界内;
若物体先前已经存在于某个节点，则先检测现在是否越出该节点的出口边界，若越出再检测位于哪个节点的入口边界内。

松散四叉树/八叉树的松散，是指出口边界比入口边界要稍微宽些（各节点的出口边界也会发生部分重叠，松散比较符合这种描述），从而使节点不容易越过出口边界，减少了物体切换节点的次数。

**用途**：

场景管理、碰撞检测、光线追踪过滤

### 层次包围盒树

 (Bounding Volume Hierarchy Based On Tree)
层次包围盒树（BVH树）是一棵多叉树，用来存储包围盒形状。
它的根节点代表一个最大的包围盒，其多个子节点则代表多个子包围盒。此外为了统一化层次包围盒树的形状，它只能存储同一种包围盒形状。

**AABB包围盒树**。把不同形状粗略用AABB形状围起来看作一个AABB形状（为了统一化形状），然后才建立层次AABB包围盒树。
在物理引擎里，由于物理模拟，大部分形状都是会动态更新的，例如位移/旋转都会改变形状。于是就又有一种支持动态更新的层次包围盒树，称之为动态层次包围盒树。它的算法核心大概：形状的位移/旋转/伸缩更新对应的叶节点，然后一级一级更新上面的节点，使它们的包围体包住子节点。

**球体包围盒树**。球体是最容易计算的一类包围盒，而且球体树构造速度可以很快，因此球体树可被用作粗略松散但快速的空间划分结构。
快速构造松散球体树的步骤（以三角形物体为例）：

1. 计算出包围所有三角边顶点的最小球体包围盒，作为根节点
2. 以球心为坐标系原点，其坐标系X轴划分出在该X轴左右的三角形，并将这些分别放入左子节点、右子节点中
3. 重复步骤1、2，最后得到一棵球体树

Bullet、Havok等物理引擎的碰撞粗测阶段，使用一种叫做**动态层次AABB包围盒树(Dynamic Bounding Volume Hierarchy Based On AABB Tree)**的结构来存储动态的AABB形状。

**应用**：
碰撞检测， 射线检测/挑选几何体， 视锥剔除， 光线追踪（Ray Tracing）过滤， 辅助BSP树构建
在BSP树的构建中，利用球体树辅助，可以将复杂度从O(Nlog²N)下降为O(NlogN)的复杂度。

### BSP树

 (Binary Space Partitioning Tree)
BSP tree是一棵二叉树，中文译名为二维空间分割树，在游戏工业算是老功臣了，第一次被应用用是在1993年的商业游戏《DOOM》上，可是随时渲染硬件的进步，基于BSP树的渲染慢慢淘汰。但是即使在今天，BSP仍是在其他分支（引擎编辑器）不可或缺的一个重要数据结构。

BSP tree在3D空间下其每个节点表示一个平面，其代表的平面将当前空间划分为前向和背向两个子空间，分别对应左儿子和右儿子。2D空间下，BSP树每个节点则表示一条边，也可以将2D空间划分成前后两部分。

3D空间下要构造一棵较平衡的BSP树，则需要尽可能每次划分出一个节点时，让其左子树节点数和右子树节点数相差不多：

1. 在一个平面形状集合里，用其中一个平面构造一个BSP树节点时，需满足它前方的平面形状数和后方的平面形状数之差 小于 一定阈值；若超过阈值则尝试用下一个形状来构造。一个麻烦的问题是当2个平面形状是相交时，即出现平面形状既可以在前方也可以在后方的情况。这时候就需要一个将该形状切割成两个子形状，从而可以一个添加在前方，一个添加在后方，避免冲突。
2. 构造完一个节点则移除对应的平面，该节点前面的平面形状和后面的平面形状则作为两个子平面形状集合。
3. 对这两个子集合以重复步骤1、2继续构造出两个子节点，并作为本节点的左右儿子。
4. 最后所有平面形状都被用于构造节点，组成了一棵BSP树。

由于需要进行N次划分，每次划分后，要在子集合里一个个挑选合适的平面（需要logN次遍历），为了评定合适又需要与子集合里所有其它形状比较前后位置（需要logN次比较），因此可以知道BSP树构造的平均时间复杂度为 O(Nlog²N)

**加速构建BSP树**：

由于BSP树构造的平均时间复杂度为O(Nlog²N)，因此其往往更适合针对静态物体进行离线构造（预处理）。但在每次对关卡进行细微的改动时，设计师可能需要等待几分钟，这时间虽然不影响程序运行效率，但拖延了开发效率。一个比较好的办法就是快速构造一棵粗略的球体树，借此结构更快的构造BSP树。

1. 我们可以先对所有平面形状构造一棵球体树，同时需要每个节点额外记录所拥有的形状（它和它所有子包围盒所代表的形状）数量，整个过程时间复杂度为O(NlogN)。
2. 然后我们按照正常构造BSP树的方法，每次划分选择一个平面形状，但是判定它前方形状数和后方形状数时不判断一个个形状在平面前后，而是判断球体包围盒在平面前后。
3. 只要一个球体包围盒完全在该平面前面或后面，那么它和它所有子包围盒代表的形状必定在平面前面或后面；若球体包围盒与平面相交，则需要分解成它所有子球体包围盒，再将这些球体包围盒与平面比较前后。
4. 由于球体包围盒节点记录了形状数量，所以容易判断球体和平面前后关系后，得到选择某个平面时前后的形状数。

### k-d树 (k-dimensional tree)

k-d树是一棵二叉树，其每个节点都代表一个k维坐标点：

1. 树的每层都是对应一个划分维度（取决于你定义第i层是哪个维度）
2. 树的每个节点代表一个超平面，该超平面垂直于当前划分维度的坐标轴，并在该维度上将空间划分为两部分，一部分在其左子树，另一部分在其右子树

实际上，k-d树就是一种特殊形式的BSP树（轴对齐的BSP树）。

用途：

划分区域（不实用）：虽然k-d树也可以划分区域，但是k-d树的构建往往非常耗时，且不支持动态构建（即发生变化需要重新构建），因此目前游戏开发还是比较少用得上。

最近邻静态目标查找（很少用，了解即可）：通过最近邻查找算法，可以剪枝了大量无需遍历的子树，效率提升得很好，其平均时间复杂度可以达到$O(n^{1−\frac{1}{k}})$，k为维度。

![Alt](./res/space_tree.png#pic_center)

## 纹理压缩算法

### DXTC

微软为DX而推出的基于block的贴图压缩格式，其主要采用调色板的原理来进行压缩。
基于$4x4$block来进行，不含有alpha通道，每个block内记录两个16bits的颜色做为基准颜色，然后解压时再使用两个基准色调制出另外两个颜色做为块内4个压缩颜色。
对于每个块内的texel，存储2bits的索引，用来指向到4个基准颜色中的一个。

### ETC

将图像中的chromatic和luminance分开存储的方式，而在解码时使用luminance对chromatic进行调制进而重现原始图像信息。

### PVRTC

PVRTC的不是基于block的方式生成的，但是却也可以理解为以block方式组织的。其生成压缩后包含两张(w/4,h/4)大小的缩略图(w,h为原始图片的宽和高，可以理解为第4级的mipmap)

## 原神

### 原神的阴影渲染

**方向光阴影**使用了常规的CSM加上基于Poisson disc的soft shadow，但将4级改为了8级。
更好的阴影效果当然也带来了更多的性能开销，更多的drawcall会带来CPU开销，更多的Cascades也会带来GPU的开销。
CPU端进行阴影缓存(shadow cache),8级cascades的前4级每帧都更新，后面4级是采用轮流更新的方式，确保每8帧所有的cascades都能至少更新一次。相当于每一帧只更新5级。
此外，在GPU端生成一张Mask贴图，在贴图里面标出阴影、半影和非影片区。阴影区和非阴影区只需要直接返回0和1就好了，只有在半影区才会去计算软阴影。这种方式减少了GPU30%的开销，甚至比只用4级还要快。

### 环境光遮蔽(AO)

针对背景的细节层次，应用**HBAO**实现效果。
对于静态的物体，实现**AO volume**，首先需要在离线的时候对需要产生AO volume的物体做一个遮挡信息的计算。这个计算是在物体的本地空间（Local space）去做的，生成的遮挡信息保存下来，在运行的时候注入到volume texture中去使用。
针对动态物体。可以看到相邻在屏风和地面，能够产生出能够反映体形和人影的投影。Capsule AO的做法就是用一些胶囊体包裹住人物的四肢和躯干，这些胶囊体和角色的骨骼动画绑定进行同步更新。然后这些胶囊体会被用来做遮挡计算，计算的时候我们把它分为无方向的环境遮挡计算，以及带方向的遮挡信息计算。

为了保证画面的干净，对AO还做了一个模糊处理（blur）。然后再上采样(UpSampling)一个全分辨率的贴图上面。所有的模糊处理和Upsample pass，我们都用了一个双边滤波Bilateral filter，确保不会有无效的AO渗透到周围的区域。
优化方式是将所有的计算都放到一个compute pass里面去做。然后通过LDS来保存blur的中间值，通过同时输出四个像素的方式，来重用相邻像素的计算。


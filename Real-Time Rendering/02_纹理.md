# Chapter.6 纹理

## 纹理管线

纹理化（texturing）是⼀种⽤于描述表⾯材质以及对表⾯进⾏修饰加⼯的有效技术，⼀种理解纹理的⽅法是，思考单个着⾊像素会如何发⽣变化。
粗糙度纹理改变了表面的粗糙度值，凹凸纹理改变了表面着色法线的方向，每个纹理都会影响最终着色方程。

![Alt](./res/texture_pipeline.png#pic_center)

纹理化始于texture mapping，这一过程通过对模型用projector function处理以获得纹理坐标(texture coordinate)。
在通过纹理坐标访问纹理之前，还需要通过一个或多个转换函数，将纹理坐标转换到纹理空间中。

具体来说，object space loaction代表了空间中模型表面的某个点，这个空间往往是该物体的局部坐标系，因为纹理总是跟着其着色的面乃至所在的物体模型移动。这个点毋庸置疑是一个三维坐标(x, y z)，**投影函数**因而根据三维坐标转换为一个纹理坐标texture coordinate space(u, v)。
纹理坐标(u, v)坐标系均在0-1范围内，但是纹理图像（纹理空间）是一段图片形式存在的离散数据，二维的形式一般是几百乘以几百的大小，所以uv坐标还需要转为一个最近邻坐标，通过corresponder function获取像素坐标texture location。
但这还没有到最后一步，最后往往需要一个value Transform function进行转换，在这个阶段会基于一些表面特性或着色法线进行转换。

管线只是起到了指导作用，并不代表需要严格遵守的工作流程。

### 投影函数 projector function

这一部分对应纹理处理的第一步是获取表面的位置，并将其投影到纹理坐标。
投影函数的最终⽬标是⽣成纹理坐标，将其作为⼀个与位置有关的函数来进⾏推导，只是其中的⼀种⽅法。

总的来说，一般分为球面投影、柱面投影和平面投影。
效果在同一个不规则物体上呈现出来差异较大。

实时渲染中通常会选择最合适的投影方式，并且计算出来相应的结果数据(uv)存储在顶点相关的数据文件上，有时候也会选择在v/f shader中实时计算，为了提高精度。投影的目标是金陵啊保证每个多边形（面）在投影的过程中尽量占据更加公平的份额，以免不同的近似跨度导致色彩畸变。

纹理坐标也不一定就是（u,v）有时候可能是(u, v, w)，甚至于（s, t, r, q），q代表了齐次坐标中的第四个分量，例如适用于装饰性聚光灯效果(gobo)

一维的纹理保证有效的同时加强了优化的效果，例如远处的山地随海拔发生的渐变，雨点的渐变。
从始至终需要明白的是，渲染的本质是服务相机的工作流，因此纹理空间的每个点需要考虑输入方向。最简单的一种情况，曲面空间上每一个点的输入方向是其法线方向。

### 转换函数 corresponder function

转换函数的应用面非常广。

转换函数将uv转换为纹理空间中的具体位置，通过在图形API中选择现有纹理的一部分，并且后续操作中只会用到这一部分数据。另一个例子是在shader中对纹理进行平移缩放和剪切等操作。
最后是一个广为认知的应用形式，即定义wrapping mode，例如clamp（边缘拉伸），mirror（重复并翻转），wrap（重复）和border（超出范围纯色）

无论是翻转还是重复，都不能简单应用于大面积的纹理铺设，例如地面，因为很容易被察觉且单调。有很多现存的方式进行处理，例如多个纹理的复合随机堆叠，将一张纹理瓦片化，选取不同的瓦片块随机组合。

最后，将uv统一化之后，对于不同的纹理图像可以进行统一的像素值索引，而不需要修改预设的纹理坐标。

### 纹理值

纹理坐标uv被输入转换函数后，转换为对应的纹理值，纹理值的形式并不固定，可以使RGB或是RGBA，然而这只是最简单的一类之一（albedo），表面粗糙度，金属度等也因此而产生。

## 图像纹理

fragment shader通过texture2D将纹理坐标转化并访问纹理，纹理坐标实际是经由GPU被转换为纹素坐标，纹理坐标的格式在不同的图形API中规范也不一样。

像素在微观的建模下是单元格，而像素本质上是单元格中心点的颜色值。为了更好的质量，像素会且应当受到其相关单元格之外的采样影响。DX9中定义每个纹素在单元格的（0, 0）处，但是在10和11中改为了每个单元格的（0.5, 0.5），和OpenGL一样。

有时候我们经常需要两个纹素坐标之间的位置，并且基于位置进行插值，有两种处理方式：截断（truncate）和摄入（round），对于截断而言，当一个像素位于（5，9）时，指的是u轴上5.0-6.0的范围，v轴上9.0-10.0的范围。

### 依赖纹理读取

依赖纹理读取（dependent texture read）包含对于移动端设备和早期的桌面GPU两个方面的定义。

对于移动端设备而言，在fs内手动计算纹理坐标并通过texture2D或类似的方式访问纹理时，而不是通过vs传入颜色坐标时，就会发生依赖纹理读取，任何对于输入纹理坐标的手动修改都会发生以来纹理读取。
对于早期的GPU而言，当一个纹理坐标依赖于之前的纹理值结果时就会发生依赖纹理读取。
例如：⼀个纹理可能会改变表⾯的着⾊法线，这反过来⼜会改变⽤于访问⽴⽅体贴图（cube map）的坐标。这种功能在早期的GPU上是受限的，甚⾄是不存在的。

现代GPU可以处理非2次幂（NPOT）的纹理，但是比较老的GPU不支持POT格式外的mipmap，不同的图形API对于纹理尺寸有着不同的上限，例如DX12允许最多$16384^2$个纹素。

### 纹理放大

对于纹理的放大采样也就是一些比较常见的方法，比如邻近过滤，双线性过滤，三次滤波。

**邻近过滤**就是在放大采样时不计算新的像素值，而是选取纹素中心最近的点。这种方法只需要为每个像素获取一个纹素即可。但是图像会非常像素化。

**双线性插值**就是非常平滑的线性插值，效果和低通滤波器很类似。

![Alt](./res/bilinear%20interpolation.png)

无论如何，对于纹理进行放大采样总是会造成视觉效果的损失，一种用于解决放大模糊的常见方法是使用细节贴图，这有点类似于之前说过的瓦片贴图的堆叠。使用另外的细节贴图覆盖在被放大的纹理上，通过将高频的重复细节和低频的模糊底色相结合，类似于使用单张高分辨率的纹理图案。

**双三次插值**（bicubic filter）的计算成本更高，但是可以在视觉上略微改善剩余的像素感。

平滑曲线被提出在一组2*2纹素之间用于放大采样，最常⽤的两个平滑曲线分别是smoothstep曲线和quintic（五次）曲线。

$$
smoothstep: \space s(x) = x^2(3-2x)
$$

$$
quintic: \space q(x) = x^3(6x^2 - 15x + 10)
$$

smoothstep曲线具有$s'(0) = 0$并且$s'(1) = 0$的性质，而且具备最基本的特性，即平滑。
quintic则更进一步，$q''(0) = 0$并且$q''(1) = 0$.

### 纹理缩小

也许第一次想象如何设计的时候，你会认为缩小采样仅仅通过卷积或者邻近插值采样就能够很好实现，但是这种方法可能会造成严重的时域锯齿（temporal aliasing），原因在于这会导致较大的像素色彩跳跃。

这种情况往往发生于较高的LOD等级下，远处的物体可能只需要几个像素点，mipmap就是为了解决这一问题而使用的技术。⽽当⼀个像素受到超过四个纹素的影响时，双线性插值就会很快失效并产⽣锯⻮。

缓解反采样问题有很多方法，除了邻近采样，下面简单介绍mipmap和SAT表三种方式。纹理的信号频率取决于所使用的纹素在渲染空间上的间隔距离，根据奈奎斯特极限，所使用的纹理信号频率不大于采样频率的一般即可，这意味着，考虑提高采样频率或者降低纹理频率是有效手段。
实际上，mipmap就是一种降低纹理信号频率的方式。

所有纹理抗锯⻮算法背后的基本思想都是相同的：对纹理进⾏预处理，创建某种数据结构，从⽽快速近似计算⼀组纹素对像素的影响。对于实时渲染⽽⾔，这些算法在执⾏过程中具有使⽤固定时间开销和资源开销的特点。

#### mipmap

**生成mipmap纹理**
mipmap实际已经广泛应用于图形软件，生成高质量mipmap亦有诀窍，常用方法是将对于2*2纹素进行平均，涉及平均计算自然就是盒滤波器。盒滤波器不仅会模糊低频信息，还会保留一些产生锯齿的高频信息，高斯、Lanczos、Kaiser或者类似的滤波器会有更好的效果。

需要注意的是，对于非线性空间中进行编码的彩色纹理，在过滤时忽略伽马校正会修改生成的mipmap贴图的感知亮度，在这种情况中，相机离物体越远就会导致物体的视觉效果越暗。所以解决方法是保证mipmap的生成要在线性空间中生成，放大和缩小的采样操作同样如此。

不仅是这个原因，一些纹理参数与最终的着色颜色之间具有非线性关系，会在第九章详细介绍。

**使用mipmap纹理**
生成mipmap后，另一个问题是实时渲染过程汇总如何访问mipmap集合，该选什么等级的mipmap纹理，因为视角问题，往往一个像素在投影过程中会包含多个纹素，覆盖的范围极有可能是不规则的，位于范围外的纹素也会对该像素最合理的颜色产生影响。我们可以这样假设，一个像素在纹理空间上的投影是一个大小、位置和方向可能任意的矩形区域。

![Alt](./res/mipmap%20access.png)

一般来说，需要是首先确定纹理细节等级，也就是常说的LOD等级，LOD等级有两种常用计算方法：
一种是取该矩形区域，较长的边对于像素的范围进行近似。参考"Pyramidal parametrics"这篇论文

另一种则更为复杂，但主流，即通过梯度值判定，四个梯度值分别是渲染空间中的xy轴沿着纹理空间的uv两个轴上的梯度值。

$$
\frac{\partial u}{\partial x}, \frac{\partial v}{\partial x} \\
$$

$$
\frac{\partial u}{\partial y}, \frac{\partial v}{\partial y}
$$

参考"Fast Filter Width Estimates with Texture Maps"。这四个分量简而言之代表了纹理坐标相对于屏幕轴向的变化量。
举个例子，$\frac{\partial u}{\partial x}$代表一个像素所对应的纹理坐标u，沿着屏幕x轴的变化量。
"MIP-Map Level Selection for Texture Mapping"考量几种不同的选择方式之间的优劣。

在shader model3.0之后，梯度值可以在fs中被直接使用。但是如果不支持的话，需要提前另外计算梯度值，只有在顶点纹理化阶段提供细节级别的信息。

根据之前所要求的，被采样的纹理空间要符合奈奎斯特极限，当一个像素包含多个纹素时，就应该提高LOD等级以便于访问尺寸更小更加模糊的mipmap层级。尽管如此，LOD并不是一个整数以指向某张固定的mipmap纹理空间，其被计算出来用来表示两个级别之间的距离分数，具体为输入三元组(u,v,d)，通过uv索引两个级别的纹理空间之间的两组被双线性插值后得到的像素值，并基于该权重d进行最后的第三次插值。

mipmap标准计算流程的成本开销是基本固定的，虽然成熟但其也有很多缺陷，比如会造成过度模糊(overblurring)，假想该矩形区域两条轴长度差异较大，即在一个方向上覆盖过大的纹素而另一个方向上只有非常少量的纹素，这相当于渲染空间中一个面相较于摄像机光线成掠射角度。但是LOD等级基于最大的梯度值，这个梯度值作为LOD等级在mipmap纹理空间上采样时，包含的是一个正方形区域内的像素信息，包含过多不合适的像素信息时就会造成模糊，这在经典的对比图像中非常显著。

![Alt](./res/LOD.png)

#### SAT表

SAT表（Summed-area Table）其实很简单, 表中任意点f(x, y)的值为该点在纹理上的像素值与f(x-1, y-1)之和，而最左上角的点为对应的像素值。

基于其计算简单的特性，只需要些许的额外计算成本和内存开销，被广泛应用于现代图形应用中，例如各向异性过滤(anisotropic filtering)。这类算法⽤于检索⾮正⽅形投影区域的纹理值，SAT对于接近⽔平⽅向或者竖直⽅向的投影区域最为有效。

在纹理化的阶段，像素的颜色通过查找SAT表和如下公式进行计算：

$$
c = \frac{s[x_{ur}, y_{ur}] - s[x_{ur}, y_{ll}] - s[x_{ll}, y_{ur}] + s[x_{ll}, y_{ll}]}{(x_{ur} - x_{ll})(y_{ur} - y_{ll})}
$$

s[x, y]代表了位于SAT查找表的具体值，而该式中分子的含义为SAT表中一片矩形区域的值，

![Alt](./res/SAT.png)

其他使⽤区域采样的算法也可以通过SAT⽅法进⾏改进。

#### 无约束的各向异性过滤

如果想要进一步改进纹理过滤的质量，最常见的方式是重用当今的mipmap硬件。基本思想是将像素单元格反向投影到纹理上，然后对于纹理上的四边形区域进行多次采样。

由上面对于mipmap的解析，纹理化过程中会在正方形区域内进行采样。这也会导致正方形区域包含了较多的无关纹素。
各向异性过滤会使用多个正方形区域进行近似，首先对于LOD的判定是四边形中较短的那个边确定，这样确保了每个mipmap的样本的平均面积更小，接着较长边用于创造一条与其平行且经过四边形中心点的各向异性线。
沿着各向异性线取两个样本，如果比例大于2：1，就取样更多。

简单介绍，这一部分也不是很懂，有空详细了解。

### 体积纹理

体积纹理就是基于三维坐标系访问的三维纹理，如今大部分GPU都支持体积纹理的mipmap，整体流程上差异不大，但是对于二维mipmap需要进行三线性插值，自然这里就需要通过四线性插值进行过滤。但是参与平均的纹素高达16个数据，精度损失的问题会更严重一些，如果就此考虑提高纹素的精度可能是权宜之计，但并非根本性的优化，甚至算不上是优化。

体积纹理需要更大的存储空间及带宽，也需要更高的计算成本，然而使用纹理坐标直接表达三维的空间位置，某种意义上跳过了纹理化管线的前几步，甚至顾及到了纹理拼接导致的扭曲接缝问题。
尽管如此，必须要意识到体积纹理的数据利用率其实极低。
对此针对性的改进，主要是数据格式上的，例如通过稀疏八叉树存储等。

### 立方体贴图 cube map

主要是用于环境映射中，第十章会详细介绍，这应该不陌生。
立方体包含六个面，访问立方体贴图需要提供一个三维向量。向量代表了从立方体中心向外发射的射线方向，向量中绝对值最大的那个分量会决定射线射向哪个面，接着另外两个分量会基于最大分量clamp至1进行相应的缩放，得出对应的立方体面上的纹理坐标。

### 纹理表示

texture atlas纹理图集，texture array纹理数组和bindless textures无绑定纹理已被广泛使用，目的是为了在实际渲染中避免无意义的纹理切换工作所带来的性能开销(以及开发成本)。
在第十九章还包含了texture streaming和texture transcoding的介绍。

为了使GPU更高效地在渲染过程中完成批处理，最好尽可能避免更改其状态，一种解决方式是将多个图像放入一个尺寸更大的纹理中，这个纹理被叫作纹理图集。一种更现代的方式就是用纹理数组，并非拼接而是批量设置为数组。

### 纹理压缩

这一部分可以参考另外的文档，写的很详细（然而离职了以后被滞留在公司了），以后有空重新扒回来。

需要注意的是一些显著性和颜色无关的纹理数据类型并不适合压缩，例如法线贴图和LUT查找表，这不难理解，法线和查找表本质只是以纹理为载体的数学数据，是包含了连续特征的离散几何信息和色彩映射关系集合的数据结构，而并非直接应用于视觉效果建设的自然（绘制）图像。粗暴的使用块压缩算法会严重破坏数据的适用性。

一种对于法线贴图压缩的方式是可以值保留x和y的分量，并在实时渲染的时候计算第三个分量，这是非常粗暴的时间换空间的方式，然而却出奇有效：一个分量一般为8bit，三个便需要24bit，大部分GPU并不支持三分量的纹理，因此三分量在传输时会被拓宽为4分量，也就是32bit，当两分量进行传输时，另外两个分量就可以存储其他的信息了。

通过BC5之类的相对低损方式进行压缩，也许能缓解，但是无法根除对视觉效果的显著影响。
参考"CryENGINE 3: Reaching the Speed of Light"，提供了一些优化方案。

"Objective Image Quality Assessment of Texture Compression"中也有一些关于压缩和视觉效果的探讨。

## 程序化纹理

我们都知道纹理是建设渲染颜色的数据载体，实际渲染依此为来源进行着色。
另一种方式就是提供数据的计算方式，例如一组或更多的函数，在着色时实时计算。这就是程序化纹理。
程序化纹理起先广泛应用于离线渲染，因为这能够减少开发和美术的负担。但是体积纹理的高昂存储成本可以通过程序化生成的方式显著优化。

湍流函数应愿而生，其主要是通过连续的2次幂频率对于数个噪声函数进行采样，并且基于不同的权重进行叠加。
然而随机噪声并非轻易生成，特别是对于高帧率的实时渲染场景。上传随机噪声纹理贴图是一种泛用的解决方法，这也是一个广泛讨论的研究领域。
"State of the Art in Procedural Noise Functions"讨论了一些研究现状。

程序化纹理是一条颠覆性的道路，因而需要考虑到方方面面，比如抗锯齿处理，mipmap这样的预计算方法肯定行不通；但是可以通过降低锯齿验证的噪声函数叠加权重来优化。

"Towards Automatic Band-Limited Procedural Shaders"回顾了一些程序化纹理的抗锯齿方案。

## 纹理动画

通过修改纹理坐标，可以动态展现纹理动画，这样的变换包含了平移，缩放，旋转和剪切等。

"Advanced Texturing Using Texture Coordinate Generation"进行了一些相关的介绍。

## 材质映射

纹理的主要用途就是用于修改材质属性，将物体渲染为现实风格或其他艺术风格。
最主要的是表面颜色，也就是反照率albedo，接着是粗糙度roughness和金属度metalness。
通过使用滤波技术，减少非线性着色输入数据造成的锯齿和走样现象，这部分在第九章中有所呈现。

## Alpha映射

Alpha通道可以用于Alpha混合或测试。
对于一些只存在1bit内容的贴图，比如树叶，周边为完全透明，内容物完全填色，通过将树或者灌木的贴图围绕中轴旋转创造廉价的3D效果。这种方式叫做镂空（cutout），通过切片，分层等方式处理1bit贴图创造3d视觉效果，且成本极低。

alpha混合（blending）用于更高精度的aloha通道场景，能够实现物体边缘的抗锯齿及透明视觉效果。但是从需求上，需要严格遵守从后向前的顺序进行渲染，且不透明面片必须优先渲染，当两个面片交叉相交时，这种处理办法就不再有效，因为每个面片都有一部分在另一者前面。
也许可以手动排序解决，但存在成千上万个镂空面片时性能成本将无法接受。

**alpha测试**是其中一种解决方式，在fs阶段主动丢弃alpha低于阈值的片元以避免z-buffer种错误标记了可见的像素。
然而这会带来新的问题，根据mipmap我们知道，生成会对2*2区域内每个通道进行卷积，然而这会导致边界区域的alpha值被完全透明区域逐步"侵蚀"，如果不进行特殊处理，在LOD级别更高的渲染场景中，镂空贴图的视觉效果会因为alpha test被丢弃大量像素而严重弱化。
[witness](http://the-witness.net/news/2010/09/computing-alpha-mipmaps/)（也是我很喜欢的独立游戏）提供了一种解决方案，包含了在nvtt中更加成熟的实现，被称为alpha to coverage和后续的其plus版本。

具体而言，为每个mipmap等级考虑一个覆盖范围$c_k$

$$
c_k = \frac{1}{n_k} \sum_i(\alpha(k, i) > \alpha_t)
$$

$n_k$表示为该等级下mipmap中的纹素个数

**双pass处理**看起来更加稳妥，


